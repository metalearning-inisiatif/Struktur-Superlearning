{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Meta Learning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/metalearning-inisiatif/Struktur-Superlearning/blob/main/STRUKTUR%20META%20LEARNING/Meta_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "Z55IGBkUP9qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Keras vs TensorFlow vs scikit-learn: What are the differences?**\n",
        "\n",
        "**Tensorflow** is the most famous library in production for deep learning models. Offers automatic differentiation to perform backpropagation smoothly, allowing you to literally build any machine learning model literally. \n",
        "**Keras** is a high-level API built on Tensorflow. It is user-friendly and helps quickly build and test a neural network with minimal lines of code. Like building simple or complex neural networks within a few minutes. **Modular** since everything in Keras can be represented as modules. \n",
        "**Scikit Learn** is a general machine learning library built on top of NumPy. It features a lot of utilities for general pre and post-processing of data. It is a library in Python used to construct traditional models.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NbLMq9cefYOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large part of our product is training and using a machine learning model. As such, we chose one of the best coding languages, Python, for machine learning. This coding language has many packages which help build and integrate ML models. For the main portion of the machine learning, we chose **PyTorch** as it is one of the highest quality ML packages for Python. PyTorch allows for extreme creativity with your models while not being too complex. Also, we chose to include **scikit-learn** as it contains many useful functions and models which can be quickly deployed. Scikit-learn is perfect for testing models, but it does not have as much flexibility as PyTorch. We also include **NumPy** and **Pandas** as these are wonderful Python packages for data manipulation. Also for testing models and depicting data, we have chosen to use **Matplotlib** and** seaborn**, a package which creates very good looking plots. Matplotlib is the standard for displaying data in Python and ML. Whereas, seaborn is a package built on top of Matplotlib which creates very visually pleasing plots."
      ],
      "metadata": {
        "id": "wWQiM31QgddT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SciKit Learn** is a general machine learning library, built on top of NumPy. It features a lot of machine learning algorithms such as support vector machines, random forests, as well as a lot of utilities for general pre- and postprocessing of data. It is not a neural network framework.\n",
        "\n",
        "**PyTorch** is a deep learning framework, consisting of\n",
        "\n",
        "     \n",
        "\n",
        "1.  A vectorized math library similar to NumPy, but with GPU support and a lot of neural network related operations (such as softmax or various kinds of activations)\n",
        "2.   Autograd - an algorithm which can automatically calculate gradients of your functions, defined in terms of the basic operations\n",
        "3. Gradient-based optimization routines for large scale optimization, dedicated to neural network optimization\n",
        "4. Neural-network related utility functions\n",
        "\n",
        "**Keras** is a higher-level deep learning framework, which abstracts many details away, making code simpler and more concise than in PyTorch or TensorFlow, at the cost of limited hackability. It abstracts away the computation backend, which can be TensorFlow, Theano or CNTK. It does not support a PyTorch backend, but that's not something unfathomable - you can consider it a simplified and streamlined subset of the above.\n",
        "\n",
        "In short, if you are going with \"classic\", non-neural algorithms, neither PyTorch nor Keras will be useful for you. If you're doing deep learning, scikit-learn may still be useful for its utility part; aside from it you will need the actual deep learning framework, where you can choose between Keras and PyTorch but you're unlikely to use both at the same time. This is very subjective, but in my view, if you're working on a novel algorithm, you're more likely to go with PyTorch (or TensorFlow or some other lower-level framework) for flexibility. If you're adapting a known and tested algorithm to a new problem setting, you may want to go with Keras for its greater simplicity and lower entry level."
      ],
      "metadata": {
        "id": "fgCxI46UioaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "#import os\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#    for filename in filenames:\n",
        "#        print(os.path.join(dirname, filename))\n",
        "\n",
        "from numpy import hstack\n",
        "from numpy import vstack\n",
        "from numpy import asarray\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        " "
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-02-04T22:32:22.575506Z",
          "iopub.execute_input": "2022-02-04T22:32:22.576957Z",
          "iopub.status.idle": "2022-02-04T22:32:24.371147Z",
          "shell.execute_reply.started": "2022-02-04T22:32:22.576800Z",
          "shell.execute_reply": "2022-02-04T22:32:24.369948Z"
        },
        "trusted": true,
        "id": "xlQnmvyC5FMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tentang make_blobs\n",
        "X, y = make_blobs(n_samples=10, centers=3, n_features=2,random_state=1)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "jpR4p912Hq9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47e25b9-d8d9-4da9-b9f6-3a79d7e5d714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a = np.array((1,2,3))\n",
        "b = np.array((4,5,6))\n",
        "print(a)\n",
        "np.hstack((a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrU7pVwEgwAt",
        "outputId": "855b998c-d528-43f5-c9f4-b5b517e2519f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array((1, 2, 3))\n",
        "b = np.array((4, 5, 6))\n",
        "print(a.shape)\n",
        "np.vstack((a,b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5_yMKAtiL2p",
        "outputId": "f90cba8c-bbc9-4f60-cd17-386c1993beaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = (1, 2)\n",
        "b=np.asarray(a)\n",
        "b"
      ],
      "metadata": {
        "id": "MSZS-lpEjngT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d936ef6-687e-4b93-dbba-6892ca28627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=list()\n",
        "b=list()\n",
        "d=list()\n",
        "e=list()\n",
        "a.append(10)\n",
        "print(a)\n",
        "a.append(20)\n",
        "a.append(5)\n",
        "print(\"List a berisi: \",a)\n",
        "c=np.asarray(a)\n",
        "print(\"a diubah menjadi array c: \", c)\n",
        "b.append(-1)\n",
        "#fungsi extend bersifat iterable dari append yang berulang ulang.\n",
        "b.extend([1])\n",
        "b.extend(a)\n",
        "print(\"List b adalah: \",b)\n",
        "c=hstack(b)\n",
        "print(\"dengan hstack b diubah dari list menjadi array :\",c)\n",
        "e=d.append(c)\n",
        "print(\"Hasil list d mengappend array c: \", e)"
      ],
      "metadata": {
        "id": "TFqoFUw9kLIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8965c4-4fd7-4545-9eee-c6ea3b6f7a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10]\n",
            "List a berisi:  [10, 20, 5]\n",
            "a diubah menjadi array c:  [10 20  5]\n",
            "List b adalah:  [-1, 1, 10, 20, 5]\n",
            "dengan hstack b diubah dari list menjadi array : [-1  1 10 20  5]\n",
            "Hasil list d mengappend array c:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "1Yus6S-oH_VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "XdQOd6iUIPDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a8cb50-f1de-4b38-fb54-585cf0883c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 1 0 0 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models():\n",
        "\tmodels = list()\n",
        "\tmodels.append(LogisticRegression(solver='liblinear'))\n",
        "\tmodels.append(DecisionTreeClassifier())\n",
        "\tmodels.append(SVC(gamma='scale', probability=True))\n",
        "\tmodels.append(GaussianNB())\n",
        "\tmodels.append(KNeighborsClassifier())\n",
        "\tmodels.append(AdaBoostClassifier())\n",
        "\tmodels.append(BaggingClassifier(n_estimators=10))\n",
        "\tmodels.append(RandomForestClassifier(n_estimators=10))\n",
        "\tmodels.append(ExtraTreesClassifier(n_estimators=10))\n",
        "\treturn models\n",
        " \n",
        "\n",
        "def get_out_of_fold_predictions1(X, y, models):\n",
        "\tmeta_X, meta_y = list(), list()\n",
        "\ti=0\n",
        "\t\n",
        "\t#definisikan dulu model kfold yang mau digunakan\n",
        "\t\n",
        "\tkfold = KFold(n_splits=5, shuffle=True)\n",
        " \n",
        "\t#_ix di bawah ini menyatakan index\n",
        "\t# dengan settingan kfold ini maka jumlah data akan dibagi menjadi 10 fold, dimana 1 fold berjumlah 120 data\n",
        "\t# Dari 10 fold ini 9 akan dijadikan training dan 1 sisanya akan dijadikan testing. \n",
        "\t# Jadi train_ix akan berjumlah 9 x 120 record = 1080 record\n",
        "\t# test_ix akan berjumlah 120 record\n",
        "\n",
        "\tfor train_ix, test_ix in kfold.split(X):\n",
        "\t\ti=i+1\n",
        "\t\tprint(\"nilai i : \",i)\n",
        "\t\t#print(train_ix,test_ix)\n",
        "\t\tfold_yhats = list()\n",
        "\t\t# get data\n",
        "\t\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
        "\t\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
        "\t\tprint(\"nilai test_y : \",test_y)\n",
        "\t\tmeta_y.extend(test_y)\n",
        "\t\t# fit and make predictions with each sub-model\n",
        "\t\tj=0\n",
        "\t\tfor model in models:\n",
        "\t\t\tj=j+1\n",
        "\t\t\tprint(\"nilai j : \",j)\n",
        "\t\t\tmodel.fit(train_X, train_y)\n",
        "\t\t\tyhat = model.predict_proba(test_X)\n",
        "\t\t\tprint(\"yhat  : \",yhat.shape)\n",
        "\t\t\tprint(yhat)\n",
        "\t \t\t# Catatan jumlah kolom yhat mengikuti banyaknya kelas dalam dataset. Dalam hal ini 3 \n",
        "\t\t\tfold_yhats.append(yhat)\n",
        "\t \n",
        "\t\tprint(\"untuk i = \",i,\" Jumlah baris fold_yhats adalah :\", len(fold_yhats),\" Jumlah kolom fold_yhats adalah :\", len(fold_yhats[0]))\n",
        "\t\t#print(\"untuk i = \",i,\" fold_yhats adalah :\", fold_yhats)\t\n",
        "\t\tmeta_X.append(hstack(fold_yhats))\n",
        "\tprint(meta_X)\n",
        "\treturn vstack(meta_X), asarray(meta_y)\n",
        " \n",
        "\n",
        "def fit_base_models(X, y, models):\n",
        "\tfor model in models:\n",
        "\t\tmodel.fit(X, y)\n",
        " \n",
        "# fit a meta model\n",
        "def fit_meta_model(X, y):\n",
        "\tmodel = LogisticRegression(solver='liblinear')\n",
        "\tmodel.fit(X, y)\n",
        "\treturn model\n",
        " \n",
        "\n",
        "def evaluate_models(X, y, models):\n",
        "\tfor model in models:\n",
        "\t\tyhat = model.predict(X)\n",
        "\t\tacc = accuracy_score(y, yhat)\n",
        "\t\tprint('%s: %.3f' % (model.__class__.__name__, acc*100))\n",
        " \n",
        "#make predictions with stacked model\n",
        "def super_learner_predictions(X, models, meta_model):\n",
        "\tmeta_X = list()\n",
        "\tfor model in models:\n",
        "\t\tyhat = model.predict_proba(X) \n",
        "\t\tmeta_X.append(yhat)\n",
        "\tmeta_X = hstack(meta_X)\n",
        "\t# predict\n",
        "\treturn meta_model.predict(meta_X)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T22:32:39.709156Z",
          "iopub.execute_input": "2022-02-04T22:32:39.709890Z",
          "iopub.status.idle": "2022-02-04T22:32:39.728353Z",
          "shell.execute_reply.started": "2022-02-04T22:32:39.709827Z",
          "shell.execute_reply": "2022-02-04T22:32:39.726579Z"
        },
        "trusted": true,
        "id": "rY0unW7-5FMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_out_of_fold_predictions(X, y, models):\n",
        "\tmeta_X, meta_y = list(), list()\n",
        "\t#definisikan dulu model kfold yang mau digunakan\n",
        "\t\n",
        "\tkfold = KFold(n_splits=10, shuffle=True)\n",
        " \n",
        "\t#_ix di bawah ini menyatakan index\n",
        "\t# dengan settingan kfold ini maka jumlah data akan dibagi menjadi 10 fold, dimana 1 fold berjumlah 120 data\n",
        "\t# Dari 10 fold ini 9 akan dijadikan training dan 1 sisanya akan dijadikan testing. \n",
        "\t# Jadi train_ix akan berjumlah 9 x 120 record = 1080 record\n",
        "\t# test_ix akan berjumlah 120 record\n",
        "\n",
        "\tfor train_ix, test_ix in kfold.split(X):\n",
        "\t\t\n",
        "\t\tfold_yhats = list()\n",
        "\t\t# get data\n",
        "\t\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
        "\t\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
        "\t\t\n",
        "\t\tmeta_y.extend(test_y)\n",
        "\t\t# fit and make predictions with each sub-model\n",
        "\t\t#Prediction dari setiap model disimpan sebagai attribut/fitur input dari superlearner model  \n",
        "\t\tfor model in models:\n",
        "\t\t\tmodel.fit(train_X, train_y)\n",
        "\t\t\tyhat = model.predict_proba(test_X)\n",
        "\t\t\t#print(\"yhat  : \",yhat.shape)\n",
        "\t \t\t# Catatan jumlah kolom yhat mengikuti banyaknya kelas dalam dataset. \n",
        "\t\t\tfold_yhats.append(yhat)\n",
        "\t\t#print(\"untuk i = \",i,\" Jumlah baris fold_yhats adalah :\", len(fold_yhats),\" Jumlah kolom fold_yhats adalah :\", len(fold_yhats[0]))\n",
        "\t\t#print(\"untuk i = \",i,\" fold_yhats adalah :\", fold_yhats)\t\n",
        "\t\tmeta_X.append(hstack(fold_yhats))\n",
        "\t#print(meta_X)\n",
        "\treturn vstack(meta_X), asarray(meta_y)\n",
        " "
      ],
      "metadata": {
        "id": "KYcQ9LPUzwxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model=get_models()\n",
        "print(Model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DhkXE5W9bQS",
        "outputId": "2a68f167-df0b-4355-d6fd-8a180db75516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogisticRegression(solver='liblinear'), DecisionTreeClassifier(), SVC(probability=True), GaussianNB(), KNeighborsClassifier(), AdaBoostClassifier(), BaggingClassifier(), RandomForestClassifier(n_estimators=10), ExtraTreesClassifier(n_estimators=10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Met_X, Met_y = get_out_of_fold_predictions1(X, y, Model)\n",
        "print(Met_X.shape)\n",
        "print(Met_y.shape)"
      ],
      "metadata": {
        "id": "dlbPbGcK-ISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Met_X)"
      ],
      "metadata": {
        "id": "ply8DJ-YxTx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangkitkan dataset klasifikasi dengan dua kelas, 2000 record dan 200 features\n",
        "X, y = make_blobs(n_samples=2000, centers=2, n_features=200, cluster_std=20,random_state=1)"
      ],
      "metadata": {
        "id": "WP0cwsLCXe0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split\n",
        "X, X_val, y, y_val = train_test_split(X, y, test_size=0.40)\n",
        "# dengan pembagian ini, 60%  data (1200) dipakai sebagai data training dan sisanya 800 data dipakai sebagai data untuk validasi.\n",
        "print('Train', X.shape, y.shape, 'Test', X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QNk2eEuXkGo",
        "outputId": "a9c3fc09-3441-4262-dbfa-c14176414989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (1200, 200) (1200,) Test (800, 200) (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisiasi models dengan get models\n",
        "models = get_models()"
      ],
      "metadata": {
        "id": "u-A3Ds4YXvzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan fungsi get out of fold predictions untuk membangkitkan input bagi superlearner\n",
        "# Prediksi dari base learner akan menjadi atribut bagi superlearner\n",
        "# jumlah record untuk superlearner adalah jumlah data test setiap Fold dikalikan dengan jumlah Fold. \n",
        "# Jadi jika k=10, dalam setiap Fold, data test berjumlah 120. Diperoleh dari 1200/10. Karena ada 10 fold, maka datatest berjumlah 10*120=1200 baris. \n",
        "\n",
        "meta_X, meta_y = get_out_of_fold_predictions(X, y, models)\n",
        "print('Meta ', meta_X.shape, meta_y.shape)\n",
        "\n",
        "#print(meta_X)\n",
        "#Jumlah kolom/atribut hasil adalah sebesar 18.\n",
        "# 18 berasal dari 9 model memprediksi peluang 2 kelas, yaitu kelas 0 dan 1\n",
        "# Jumlah baris adalah 10*120=1200. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2BcVeYKX2s-",
        "outputId": "41af47e6-b4b3-420a-d6b0-ab01b899a68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta  (1200, 18) (1200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit base models\n",
        "# Tahapan ini adalah membandingkan akurasi antara base models dan superlearner model.\n",
        "fit_base_models(X, y, models)\n",
        "# fit the meta model\n",
        "# Metamodel difit menggunakan k-fold prediction yang dihasilkan oleh base learner.\n",
        "meta_model = fit_meta_model(meta_X, meta_y)"
      ],
      "metadata": {
        "id": "z-eec0m5X-XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate base models\n",
        "# disini base models dievaluasi keakuratan prediksi kelas.\n",
        "evaluate_models(X_val, y_val, models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMm8xn-AYDzc",
        "outputId": "1c1809f7-314e-460c-bbe0-8f7b8bd8782a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression: 99.875\n",
            "DecisionTreeClassifier: 78.250\n",
            "SVC: 99.875\n",
            "GaussianNB: 99.875\n",
            "KNeighborsClassifier: 98.875\n",
            "AdaBoostClassifier: 95.000\n",
            "BaggingClassifier: 87.500\n",
            "RandomForestClassifier: 89.750\n",
            "ExtraTreesClassifier: 90.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate meta model\n",
        "# Sebelum meta model melakukan prediksi terhadap X_Val, base models diberi kesempatan dulu untuk melakukan \n",
        "# Predict_proba terhadap X_Val. Hasil predict_proba ini menjadi input bagi superlearner.\n",
        "\n",
        "yhat = super_learner_predictions(X_val, models, meta_model)\n",
        "print('Akurasi Super Learner: %.3f' % (accuracy_score(y_val, yhat) * 100))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T22:32:48.217571Z",
          "iopub.execute_input": "2022-02-04T22:32:48.218055Z",
          "iopub.status.idle": "2022-02-04T22:33:27.865336Z",
          "shell.execute_reply.started": "2022-02-04T22:32:48.218008Z",
          "shell.execute_reply": "2022-02-04T22:33:27.856886Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJt6AdyI5FMf",
        "outputId": "1f5800a6-9090-4590-dc48-a261a41d3f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Super Learner: 99.875\n"
          ]
        }
      ]
    }
  ]
}